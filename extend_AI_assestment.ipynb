{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ca79b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import detection\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "from sklearn.metrics.pairwise import cosine_distances,pairwise_distances,cosine_similarity\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3de4f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(image_name):\n",
    "    \"\"\"\n",
    "        Get embeddings for a single instance of image\n",
    "\n",
    "    :type image_name: pillow image\n",
    "    \"\"\"\n",
    "    # Run some image processing steps. Resize and normalize\n",
    "    scaler = transforms.Resize((224, 224))\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    to_tensor = transforms.ToTensor()\n",
    "\n",
    "    # Load resnet pretrained model\n",
    "    model_all = models.resnet152(pretrained=True)\n",
    "    # Remove the last classification layer and create a new model\n",
    "    model = torch.nn.Sequential(*list(model_all.children())[:-1])\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    if isinstance(image_name, str):\n",
    "        img = Image.open(image_name)\n",
    "    else:\n",
    "        img = image_name\n",
    "    # Create a PyTorch Variable with the transformed image, run preprocessing steps\n",
    "    t_img = Variable(normalize(to_tensor(scaler(img))).unsqueeze(0))\n",
    "    # The 'avgpool' layer has an output size of 512\n",
    "    my_embedding = torch.zeros(512)\n",
    "    # embedding is a 512 dimension 1D vector\n",
    "    my_embedding = model(t_img).squeeze()\n",
    "    return my_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512c4d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sliding_window(image, stepSize_x, stepSize_y, windowSize):\n",
    "    # slide a window across the image\n",
    "    for y in range(0, image.shape[0], stepSize_y):\n",
    "        for x in range(0, image.shape[1], stepSize_x):\n",
    "            # yield the current window\n",
    "            yield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b67061",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    image_name_1 = './data/2021-04-07 21_39_06_exai_rpi_001_85.jpg'\n",
    "    image_name_2 = './data/2021-04-07 21_37_18_exai_rpi_001_58.jpg'\n",
    "    image_name_3 = './data/2021-04-07 21_40_10_exai_rpi_001_101.jpg'\n",
    "    image_name_4 = './data/2021-04-07 21_45_00_exai_rpi_004_176.jpg'\n",
    "    image_name_5 = './data/2021-04-07 21_43_40_exai_rpi_004_156.jpg'\n",
    "    image_name_6 = './data/2021-04-07 21_39_20_exai_rpi_004_91.jpg'\n",
    "    image_name_7 = './data/2021-04-07 21_36_40_exai_rpi_004_51.jpg'\n",
    "    \n",
    "\n",
    "    all_images = [image_name_1, image_name_2, image_name_3, image_name_4, image_name_5, image_name_6, image_name_7]\n",
    "\n",
    "\n",
    "    for index_img, image_name in enumerate(all_images):\n",
    "        # Read the entire image\n",
    "        whole_image = cv2.imread(image_name)\n",
    "        # Get the list of sliding window images\n",
    "        all_imgs = list(sliding_window(whole_image,  96, 122, (96*4, 122*3)))\n",
    "\n",
    "        count = 0\n",
    "        all_embeds = []\n",
    "        x_pos = []\n",
    "        y_pos = []\n",
    "        # Here we give the sliding window images to the network one by one. Batching could be more efficient.\n",
    "        # In this loop, convert opencv image to pillow image and get the embedding for it\n",
    "        for img in all_imgs:\n",
    "            color_converted = cv2.cvtColor(img[2], cv2.COLOR_BGR2RGB)\n",
    "            pil_image_2 = Image.fromarray(color_converted)\n",
    "            count = count + 1\n",
    "            embeds = get_vector(pil_image_2)\n",
    "            all_embeds.append(embeds.detach().numpy())\n",
    "\n",
    "        # Stack all embedding and get all x,y positions of sliding window images.\n",
    "        all_embeds = np.stack(all_embeds, axis = 0)\n",
    "        np.save('./data/embeddings/embedding' + str(index_img) + '.npy', all_embeds)\n",
    "\n",
    "        x_pos_set = np.array([img[0] for img in all_imgs])\n",
    "        y_pos_set = np.array([img[1] for img in all_imgs])\n",
    "\n",
    "        # Obtain cosine similarity matrix of all embeddings.\n",
    "        cosine_sim_mat =  cosine_similarity(all_embeds)\n",
    "        # Take the mean similarity score.\n",
    "        mean_distances = np.mean(cosine_sim_mat, axis=0)\n",
    "\n",
    "        count = 0\n",
    "        # Loop over mean distances, if the mean distance is below the threshold. Tag the image patch as anomaly and save the patch\n",
    "        for inds, distances in enumerate(mean_distances):\n",
    "            if 0.65 > distances:\n",
    "                window_name = 'image'\n",
    "                count = count + 1\n",
    "                print(distances)\n",
    "                print(count)\n",
    "                print(x_pos_set[inds])\n",
    "                print(y_pos_set[inds])\n",
    "                # Using cv2.imshow() method\n",
    "                # Displaying the image\n",
    "                cv2.imshow('test', mat = all_imgs[inds][2])\n",
    "                cv2.imwrite('./data/embeddings/detected_patches_' + str(index_img) + '_' + str(count)+ '.jpg', all_imgs[inds][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3ce6b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a088f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
