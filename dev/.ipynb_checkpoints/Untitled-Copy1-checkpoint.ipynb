{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4563df39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from patchify import patchify, unpatchify\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a26f90bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r'E:\\extend-ai-ml-assessment\\data'\n",
    "PATCH_SIZE_H = 128\n",
    "PATCH_SIZE_W = 128\n",
    "file_names = [i for i in os.listdir(DATA_PATH) if '.jpg' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bccf1469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copyingPatches(patches_img, img_name, folder='patches'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Reading and copying patches \n",
    "    \n",
    "    Args:\n",
    "    patches_img(arr): Patches of the input numpy image\n",
    "    folder (str): Path of the folder \n",
    "    working_patches(str):Destination output to copy the content\n",
    "    \n",
    "    Returns:\n",
    "    N/A \n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(patches_img.shape[0]):\n",
    "        for j in range(patches_img.shape[1]):\n",
    "            single_patch_img = patches_img[i, j, 0, :, :, :]\n",
    "            os.makedirs(os.path.join(DATA_PATH, folder), exist_ok=True)\n",
    "            cv2.imwrite(os.path.join(DATA_PATH, folder, f'{img_name}_' + '_'+ str(i).zfill(2) + '_' + str(j).zfill(2) + '.png'), single_patch_img)  # Save as PNG, not JPEG for keeping the quality.\n",
    "\n",
    "#         for filename in glob.glob(os.path.join(\"patches\", '*.*')):\n",
    "#             shutil.copy(filename, working_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59551304",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in file_names:\n",
    "    img = cv2.imread(os.path.join(DATA_PATH, name))\n",
    "#     print(img.shape)\n",
    "    SIZE_X = (img.shape[1]//PATCH_SIZE_W)*PATCH_SIZE_W #Nearest size divisible by our patch size\n",
    "    SIZE_Y = (img.shape[0]//PATCH_SIZE_H)*PATCH_SIZE_H #Nearest size divisible by our patch size\n",
    "    img=cv2.resize(img,(SIZE_X,SIZE_Y))\n",
    "    \n",
    "    patches_img = patchify(img, (PATCH_SIZE_H, PATCH_SIZE_W, 3), step=PATCH_SIZE_H)\n",
    "    copyingPatches(patches_img, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8edb80f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT= os.path.join(DATA_PATH, 'patches') #path of the original folder\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, 'train')\n",
    "VAL_PATH = os.path.join(DATA_PATH, 'val')\n",
    "ANAM_PATH = os.path.join(DATA_PATH, 'anomalies') \n",
    "\n",
    "os.makedirs(os.path.join(DATA_PATH, 'train', 'images'), exist_ok=True)\n",
    "\n",
    "os.makedirs(os.path.join(DATA_PATH, 'val', 'images'), exist_ok=True)\n",
    "\n",
    "file_names = os.listdir(ROOT)\n",
    "\n",
    "np.random.shuffle(file_names)\n",
    "\n",
    "test_ratio = 0.15\n",
    "\n",
    "train_file_names, test_file_names = np.split(np.array(file_names),\n",
    "                                                      [int(len(file_names)* (1 - test_ratio))])\n",
    "\n",
    "train_file_names = [os.path.join(ROOT, name) for name in train_file_names.tolist()]\n",
    "test_file_names = [os.path.join(ROOT, name) for name in test_file_names.tolist()]\n",
    "\n",
    "for name in train_file_names:\n",
    "    shutil.copy(name, os.path.join(TRAIN_PATH, 'images'))\n",
    "\n",
    "for name in test_file_names:\n",
    "    shutil.copy(name, os.path.join(VAL_PATH, 'images'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3ecee41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1733 images belonging to 1 classes.\n",
      "Found 306 images belonging to 1 classes.\n",
      "Found 61 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "#Size of our input images\n",
    "SIZE = 128\n",
    "\n",
    "#############################################################################\n",
    "#Define generators for training, validation and also anomaly data.\n",
    "\n",
    "batch_size = 64\n",
    "datagen = ImageDataGenerator(rescale=1./255,\n",
    "                            rotation_range=40,\n",
    "                            width_shift_range=0.2,\n",
    "                            height_shift_range=0.2,\n",
    "                            shear_range=0.2,\n",
    "                            zoom_range=0.2,\n",
    "                            vertical_flip = True,\n",
    "                            horizontal_flip=True,\n",
    "                            brightness_range = [0.2, 0.8],\n",
    "                            fill_mode='nearest')\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    target_size=(SIZE, SIZE),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='input'\n",
    "    )\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    VAL_PATH,\n",
    "    target_size=(SIZE, SIZE),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='input'\n",
    "    )\n",
    "\n",
    "anomaly_generator = datagen.flow_from_directory(\n",
    "    ANAM_PATH,\n",
    "    target_size=(SIZE, SIZE),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='input'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "573067e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_35 (Conv2D)          (None, 128, 128, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 64, 64, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 64, 64, 32)        18464     \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 32, 32, 16)        4624      \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 16, 16, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 16, 16, 16)        2320      \n",
      "                                                                 \n",
      " up_sampling2d_15 (UpSamplin  (None, 32, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 32, 32, 32)        4640      \n",
      "                                                                 \n",
      " up_sampling2d_16 (UpSamplin  (None, 64, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 64, 64, 64)        18496     \n",
      "                                                                 \n",
      " up_sampling2d_17 (UpSamplin  (None, 128, 128, 64)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 128, 128, 3)       1731      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52,067\n",
      "Trainable params: 52,067\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Define the autoencoder. \n",
    "#Try to make the bottleneck layer size as small as possible to make it easy for\n",
    "#density calculations and also picking appropriate thresholds. \n",
    "SIZE = 128\n",
    "#Encoder\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(SIZE, SIZE, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "#Decoder\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(3, (3, 3), activation='sigmoid', padding='same'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33873c5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "28/28 [==============================] - 9s 292ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 2/2000\n",
      "28/28 [==============================] - 8s 287ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 3/2000\n",
      "28/28 [==============================] - 8s 285ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 4/2000\n",
      "28/28 [==============================] - 8s 294ms/step - loss: 8.1000e-04 - mse: 8.1000e-04 - val_loss: 7.2090e-04 - val_mse: 7.2090e-04\n",
      "Epoch 5/2000\n",
      "28/28 [==============================] - 8s 294ms/step - loss: 6.7201e-04 - mse: 6.7201e-04 - val_loss: 7.3757e-04 - val_mse: 7.3757e-04\n",
      "Epoch 6/2000\n",
      "28/28 [==============================] - 8s 287ms/step - loss: 5.9779e-04 - mse: 5.9779e-04 - val_loss: 5.7418e-04 - val_mse: 5.7418e-04\n",
      "Epoch 7/2000\n",
      " 9/28 [========>.....................] - ETA: 4s - loss: 6.0469e-04 - mse: 6.0469e-04"
     ]
    }
   ],
   "source": [
    "#Fit the model. \n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=100)\n",
    "\n",
    "history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=2000,\n",
    "        validation_data=validation_generator,\n",
    "        shuffle = True,\n",
    "        callbacks=[callback])\n",
    "model.save('anamoly_detector.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5b72ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1efedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all batches generated by the datagen and pick a batch for prediction\n",
    "#Just to test the model. \n",
    "data_batch = []  #Capture all training batches as a numpy array\n",
    "img_num = 0\n",
    "while img_num <= train_generator.batch_index:   #gets each generated batch of size batch_size\n",
    "    data = train_generator.next()\n",
    "    data_batch.append(data[0])\n",
    "    img_num = img_num + 1\n",
    "\n",
    "predicted = model.predict(data_batch[0])  #Predict on the first batch of images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24ee76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check, view few images and corresponding reconstructions\n",
    "image_number = random.randint(0, predicted.shape[0])\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(data_batch[0][image_number])\n",
    "plt.subplot(122)\n",
    "plt.imshow(predicted[image_number])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abba396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us examine the reconstruction error between our validation data (good/normal images)\n",
    "# and the anomaly images\n",
    "validation_error = model.evaluate_generator(validation_generator)\n",
    "anomaly_error = model.evaluate_generator(anomaly_generator)\n",
    "\n",
    "print(\"Recon. error for the validation (normal) data is: \", validation_error)\n",
    "print(\"Recon. error for the anomaly data is: \", anomaly_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082fd44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us extract (or build) the encoder network, with trained weights.\n",
    "#This is used to get the compressed output (latent space) of the input image. \n",
    "#The compressed output is then used to calculate the KDE\n",
    "\n",
    "encoder_model = Sequential()\n",
    "encoder_model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(SIZE, SIZE, 3), weights=model.layers[0].get_weights()) )\n",
    "encoder_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "encoder_model.add(Conv2D(32, (3, 3), activation='relu', padding='same', weights=model.layers[2].get_weights()))\n",
    "encoder_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "encoder_model.add(Conv2D(16, (3, 3), activation='relu', padding='same', weights=model.layers[4].get_weights()))\n",
    "encoder_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7426bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate KDE using sklearn\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "#Get encoded output of input images = Latent space\n",
    "encoded_images = encoder_model.predict_generator(train_generator)\n",
    "\n",
    "# Flatten the encoder output because KDE from sklearn takes 1D vectors as input\n",
    "encoder_output_shape = encoder_model.output_shape #Here, we have 16x16x16\n",
    "out_vector_shape = encoder_output_shape[1]*encoder_output_shape[2]*encoder_output_shape[3]\n",
    "\n",
    "encoded_images_vector = [np.reshape(img, (out_vector_shape)) for img in encoded_images]\n",
    "\n",
    "#Fit KDE to the image latent data\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(encoded_images_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdf8a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate density and reconstruction error to find their means values for\n",
    "#good and anomaly images. \n",
    "#We use these mean and sigma to set thresholds. \n",
    "def calc_density_and_recon_error(batch_images):\n",
    "    \n",
    "    density_list=[]\n",
    "    recon_error_list=[]\n",
    "    for im in range(0, batch_images.shape[0]-1):\n",
    "        \n",
    "        img  = batch_images[im]\n",
    "        img = img[np.newaxis, :,:,:]\n",
    "        encoded_img = encoder_model.predict([[img]]) # Create a compressed version of the image using the encoder\n",
    "        encoded_img = [np.reshape(img, (out_vector_shape)) for img in encoded_img] # Flatten the compressed image\n",
    "        density = kde.score_samples(encoded_img)[0] # get a density score for the new image\n",
    "        reconstruction = model.predict([[img]])\n",
    "        reconstruction_error = model.evaluate([reconstruction],[[img]], batch_size = 1)[0]\n",
    "        density_list.append(density)\n",
    "        recon_error_list.append(reconstruction_error)\n",
    "        \n",
    "    average_density = np.mean(np.array(density_list))  \n",
    "    stdev_density = np.std(np.array(density_list)) \n",
    "    \n",
    "    average_recon_error = np.mean(np.array(recon_error_list))  \n",
    "    stdev_recon_error = np.std(np.array(recon_error_list)) \n",
    "    \n",
    "    return average_density, stdev_density, average_recon_error, stdev_recon_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dae84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get average and std dev. of density and recon. error for uninfected and anomaly (parasited) images. \n",
    "#For this let us generate a batch of images for each. \n",
    "train_batch = train_generator.next()[0]\n",
    "anomaly_batch = anomaly_generator.next()[0]\n",
    "\n",
    "uninfected_values = calc_density_and_recon_error(train_batch)\n",
    "anomaly_values = calc_density_and_recon_error(anomaly_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a1fca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"uninfected_values: {uninfected_values}\")\n",
    "print(f\"anomaly_values: {anomaly_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6099a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, input unknown images and sort as Good or Anomaly\n",
    "def check_anomaly(img_path):\n",
    "    density_threshold = 2500 #Set this value based on the above exercise\n",
    "    reconstruction_error_threshold = 0.004 # Set this value based on the above exercise\n",
    "    img  = Image.open(img_path)\n",
    "    img = np.array(img.resize((128,128), Image.ANTIALIAS))\n",
    "    plt.imshow(img)\n",
    "    img = img / 255.\n",
    "    img = img[np.newaxis, :,:,:]\n",
    "    encoded_img = encoder_model.predict([[img]]) \n",
    "    encoded_img = [np.reshape(img, (out_vector_shape)) for img in encoded_img] \n",
    "    density = kde.score_samples(encoded_img)[0] \n",
    "\n",
    "    reconstruction = model.predict([[img]])\n",
    "    reconstruction_error = model.evaluate([reconstruction],[[img]], batch_size = 1)[0]\n",
    "\n",
    "    if density < density_threshold or reconstruction_error > reconstruction_error_threshold:\n",
    "        print(\"The image is an anomaly\")\n",
    "        \n",
    "    else:\n",
    "        print(\"The image is NOT an anomaly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85199075",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load a couple of test images and verify whether they are reported as anomalies.\n",
    "import glob\n",
    "para_file_paths = glob.glob('/content/cell_images/Parasitized/images/*')\n",
    "uninfected_file_paths = glob.glob('/content/cell_images/uninfected_train/images/*')\n",
    "\n",
    "#Anomaly image verification\n",
    "num=random.randint(0,len(para_file_paths)-1)\n",
    "check_anomaly(para_file_paths[num])\n",
    "\n",
    "#Good/normal image verification\n",
    "num=random.randint(0,len(para_file_paths)-1)\n",
    "check_anomaly(uninfected_file_paths[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7b7049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fab7890",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfod",
   "language": "python",
   "name": "tfod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
