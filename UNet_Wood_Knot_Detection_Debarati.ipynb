{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNet_Wood_Knot_Detection_Debarati.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/debarati-nath/Detection_of_Wood_Knot/blob/main/UNet_Wood_Knot_Detection_Debarati.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTMKeufe1B5R",
        "outputId": "a809d402-5f07-47f1-ba7d-8de4546526f4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53NlxR3O0cQq"
      },
      "source": [
        "**Project on Detection of Wood Knots**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T40NGlbgeIIc"
      },
      "source": [
        "# Import Libraries\n",
        "\n",
        "import albumentations\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from functools import partial\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgb2gray\n",
        "from sklearn.externals._pilutil import bytescale\n",
        "from skimage.util import crop\n",
        "from skimage.transform import rescale, rotate\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "from typing import List, Callable, Tuple\n",
        "from torch.utils import data\n",
        "from tqdm import tqdm, trange"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez6Tq2JdrwPq"
      },
      "source": [
        "# Create random seed\n",
        "random_seed = 42"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2Q95hj1r575"
      },
      "source": [
        "All functions and classes are written for data augmentation and loading dataset from a specific folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPXJxzYITqHo"
      },
      "source": [
        "#####################Data augmentation helpers start here#######################\n",
        "################################################################################\n",
        "\n",
        "def normalize_data(inp: np.ndarray):\n",
        "    \"\"\"\n",
        "    Normalize the images.\n",
        "    Squash image input to the value range [0, 1] and no clipping was used.\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    inp_out = (inp - np.min(inp)) / np.ptp(inp)\n",
        "\n",
        "    return inp_out\n",
        "\n",
        "def create_dense_target(tar: np.ndarray):\n",
        "  \"\"\"\n",
        "\n",
        "    Dense target was created.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  classes = np.unique(tar)\n",
        "  dummy = np.zeros_like(tar)\n",
        "  \n",
        "  for idx, value in enumerate(classes):\n",
        "    \n",
        "    mask = np.where(tar == value)\n",
        "    dummy[mask] = idx\n",
        "    \n",
        "    return dummy\n",
        "\n",
        "class Repr():\n",
        "    \"\"\"\n",
        "    Evaluable string representation of an object. This class calls another \n",
        "    functions for doing specific performance.\n",
        "    \"\"\"\n",
        "\n",
        "    def __repr__(self): \n",
        "      return f'{self.__class__.__name__}: {self.__dict__}'\n",
        "\n",
        "\n",
        "\n",
        "class FunctionWrapperDouble(Repr):\n",
        "    \"\"\"\n",
        "    A function wrapper that returns a partial for an input-target pair. This \n",
        "    class calls another class for calling another function for doing specific \n",
        "    performance so that Repr class was not initialized here.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, function: Callable, input: bool = True, \n",
        "                 target: bool = False, *args, **kwargs):\n",
        "      \n",
        "        self.function = partial(function, *args, **kwargs)\n",
        "        self.input = input\n",
        "        self.target = target\n",
        "\n",
        "    def __call__(self, inp: np.ndarray, tar: dict):\n",
        "\n",
        "        if self.input: inp = self.function(inp)\n",
        "        if self.target: tar = self.function(tar)\n",
        "\n",
        "        return inp, tar\n",
        "\n",
        "\n",
        "class Compose():\n",
        "    \"\"\"\n",
        "    Baseclass was created for composing different transforms together.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, transforms: List[Callable]):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __repr__(self): \n",
        "      return str([transform for transform in self.transforms])\n",
        "\n",
        "\n",
        "class ComposeDouble(Compose):\n",
        "    \"\"\"\n",
        "    Composes transforms for input-target pairs. This class calls Compose class\n",
        "    for composing different transforms together.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __call__(self, inp: np.ndarray, target: dict):\n",
        "\n",
        "        for t in self.transforms:\n",
        "            inp, target = t(inp, target)\n",
        "        return inp, target\n",
        "\n",
        "\n",
        "class AlbuSeg2d(Repr):\n",
        "    \"\"\"\n",
        "\n",
        "    Wrapper for albumentations' segmentation-compatible 2D augmentations.\n",
        "    Wraps an augmentation so it can be used within the provided transform \n",
        "    pipeline. This class calls Repr class for doing the albumentations' \n",
        "    segmentation-compatible 2D augmentaions\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, albumentation: Callable):\n",
        "        self.albumentation = albumentation\n",
        "\n",
        "    def __call__(self, inp: np.ndarray, tar: np.ndarray):\n",
        "\n",
        "        # Input and target\n",
        "\n",
        "        out_dict = self.albumentation(image=inp, mask=tar)\n",
        "        input_out = out_dict['image']\n",
        "        target_out = out_dict['mask']\n",
        "\n",
        "        return input_out, target_out\n",
        "\n"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFwhH6ooJIKF"
      },
      "source": [
        "########################DataLoader helpers start here###########################\n",
        "################################################################################\n",
        "\n",
        "# Function for loading inputs and targets from a specific directory\n",
        "\n",
        "def get_filenames_of_path(path: pathlib.Path, ext: str = \"*\"):\n",
        "    \"\"\"\n",
        "\n",
        "    Returns a list of files in a directory/path. pathlib was used here.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    filenames = [file for file in path.glob(ext) if file.is_file()]\n",
        "    return filenames\n",
        "\n",
        "# Class is created for loading and transforming dataset.\n",
        "\n",
        "class Data_Augmentation(data.Dataset):\n",
        "    \"\"\"\n",
        "\n",
        "    Dataset were imported.\n",
        "    Transformation was done.\n",
        "    Torch from numpy were done.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, inputs: list, targets: list, transform=None):\n",
        "\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "        self.transform = transform\n",
        "        self.inputs_dtype = torch.float32\n",
        "        # Use torch.int64 as long for targets\n",
        "        self.targets_dtype = torch.long\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "\n",
        "        # Select the sample\n",
        "        input_id = self.inputs[index]\n",
        "        target_id = self.targets[index]\n",
        "\n",
        "        # Load input and target\n",
        "        x, y = imread(str(input_id)), rgb2gray(imread(str(target_id)))\n",
        "\n",
        "        # Preprocessing if the transformation function is given. \n",
        "        # Otherwise returns the input-target pair.\n",
        "        if self.transform is not None:\n",
        "            x, y = self.transform(x, y)\n",
        "\n",
        "        # Convert torch from numpy\n",
        "        x, y = torch.from_numpy(x).type(self.inputs_dtype),\\\n",
        "                               torch.from_numpy(y).type(self.targets_dtype)\n",
        "\n",
        "        return x, y"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYV5e1K84VTF"
      },
      "source": [
        "*U-net model was created here. Firstly, different function was created for convolution layer separately and call them in U-Net class*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4uPiRKtDGLf"
      },
      "source": [
        "###################################U-Net class##################################\n",
        "################################################################################\n",
        "\n",
        "class UNet(nn.Module):\n",
        "  \"\"\"\n",
        "  Two convolution blocks were created with batchnormalization and relu function\n",
        "  called blockconv. bottleneck was the last down conv and then ConvTrans2d was \n",
        "  used for upsampling. Maxpooling layer was also used between two blockconv \n",
        "  layers.\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self, in_channels=3, out_channels=2, init_features=32):\n",
        "    super(UNet, self).__init__()\n",
        "    \n",
        "    features = init_features\n",
        "    self.encoder_1 = UNet.blockconv(in_channels, features, name=\"enc_1\")\n",
        "    self.pool_1 = nn.MaxPool2d(kernel_size=2, stride=2) # MaxPool layer\n",
        "    self.encoder_2 = UNet.blockconv(features, features * 2, name=\"enc_2\")\n",
        "    self.pool_2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.encoder_3 = UNet.blockconv(features * 2, features * 4, name=\"enc_3\")\n",
        "    self.pool_3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.encoder_4 = UNet.blockconv(features * 4, features * 8, name=\"enc_4\")\n",
        "    self.pool_4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    self.bottleneck = UNet.blockconv(features * 8, \n",
        "                                     features * 16, \n",
        "                                     name=\"bottleneck\")\n",
        "    # Transpose layer\n",
        "    self.upconv_4 = nn.ConvTranspose2d(features * 16, \n",
        "                                      features * 8, \n",
        "                                      kernel_size=2, \n",
        "                                      stride=2)\n",
        "    self.decoder_4 = UNet.blockconv((features * 8) * 2, \n",
        "                                   features * 8, \n",
        "                                  name=\"dec_4\")\n",
        "    self.upconv_3 = nn.ConvTranspose2d(features * 8, \n",
        "                                      features * 4, \n",
        "                                      kernel_size=2, \n",
        "                                      stride=2)\n",
        "    self.decoder_3 = UNet.blockconv((features * 4) * 2, features * 4, \n",
        "                                   name=\"dec_3\")\n",
        "    self.upconv_2 = nn.ConvTranspose2d(features * 4, features * 2, \n",
        "                                      kernel_size=2, stride=2)\n",
        "    self.decoder_2 = UNet.blockconv((features * 2) * 2, features * 2, \n",
        "                                    name=\"dec_2\")\n",
        "    self.upconv_1 = nn.ConvTranspose2d(features * 2, features, \n",
        "                                      kernel_size=2, stride=2)\n",
        "    self.decoder_1 = UNet.blockconv(features * 2, features, name=\"dec_1\")\n",
        "\n",
        "    self.conv = nn.Conv2d(in_channels=features, out_channels=out_channels, \n",
        "                          kernel_size=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    enc_1 = self.encoder_1(x)\n",
        "    enc_2 = self.encoder_2(self.pool_1(enc_1))\n",
        "    enc_3 = self.encoder_3(self.pool_2(enc_2))\n",
        "    enc_4 = self.encoder_4(self.pool_3(enc_3))\n",
        "\n",
        "    bottleneck = self.bottleneck(self.pool_4(enc_4))\n",
        "\n",
        "    dec_4 = self.upconv_4(bottleneck)\n",
        "    dec_4 = torch.cat((dec_4, enc_4), dim=1)\n",
        "    dec_4 = self.decoder_4(dec_4)\n",
        "    dec_3 = self.upconv_3(dec_4)\n",
        "    dec_3 = torch.cat((dec_3, enc_3), dim=1)\n",
        "    dec_3 = self.decoder_3(dec_3)\n",
        "    dec_2 = self.upconv_2(dec_3)\n",
        "    dec_2 = torch.cat((dec_2, enc_2), dim=1)\n",
        "    dec_2 = self.decoder_2(dec_2)\n",
        "    dec_1 = self.upconv_1(dec_2)\n",
        "    dec_1 = torch.cat((dec_1, enc_1), dim=1)\n",
        "    dec_1 = self.decoder_1(dec_1)\n",
        "    return torch.sigmoid(self.conv(dec_1))\n",
        "\n",
        "  # Function is for the convolution layers\n",
        "  def blockconv(in_channels, features, name):\n",
        "    return nn.Sequential(nn.Conv2d(in_channels=in_channels,\n",
        "                                   out_channels=features,\n",
        "                                   kernel_size=3, padding=1,\n",
        "                                   bias=False),\n",
        "                        nn.BatchNorm2d(num_features=features), # Normalization\n",
        "                        nn.ReLU(inplace=True), # Activation\n",
        "                        nn.Conv2d(in_channels=features,\n",
        "                                  out_channels=features,\n",
        "                                  kernel_size=3,\n",
        "                                 padding=1,\n",
        "                                 bias=False),\n",
        "                        nn.BatchNorm2d(num_features=features), # Normalization\n",
        "                        nn.ReLU(inplace=True)) # Activation\n",
        "\n",
        "\n",
        "          "
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_aP-YZo93ao"
      },
      "source": [
        "Class with functions for training and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9Q24SX8cRKC"
      },
      "source": [
        "###########################Trainer class for training###########################\n",
        "################################################################################\n",
        "\n",
        "class Trainer:\n",
        "  \"\"\"\n",
        "  3 functions were written for training and validating.\n",
        "  \"\"\"\n",
        "  def __init__(\n",
        "        self,\n",
        "        model: torch.nn.Module,\n",
        "        criterion: torch.nn.Module,\n",
        "        optimizer: torch.optim.Optimizer,\n",
        "        training_DataLoader: torch.utils.data.Dataset,\n",
        "        validation_DataLoader: torch.utils.data.Dataset = None,\n",
        "        epochs: int = 100,\n",
        "        epoch: int = 0):\n",
        "\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.training_DataLoader = training_DataLoader\n",
        "        self.validation_DataLoader = validation_DataLoader\n",
        "        self.epochs = epochs\n",
        "        self.epoch = epoch\n",
        "\n",
        "        self.training_loss = []\n",
        "        self.validation_loss = []\n",
        "        self.learning_rate = []\n",
        "\n",
        "  def run_trainer(self):\n",
        "\n",
        "        progressbar = trange(self.epochs, desc=\"Progress\")\n",
        "        for i in progressbar:\n",
        "\n",
        "            self.epoch += 1  # Epoch counter\n",
        "\n",
        "            self._train()   # Train block\n",
        "\n",
        "            if self.validation_DataLoader is not None:\n",
        "                self._validate()   # Validation block\n",
        "\n",
        "        return self.training_loss, self.validation_loss, self.learning_rate\n",
        "\n",
        "  def _train(self):\n",
        "\n",
        "\n",
        "        self.model.train()  # Train mode\n",
        "        train_losses = []  # Accumulate the losses here\n",
        "        batch_iter = tqdm(\n",
        "            enumerate(self.training_DataLoader),\n",
        "            \"Training\",\n",
        "            total=len(self.training_DataLoader),\n",
        "            leave=False,\n",
        "        )\n",
        "\n",
        "        for i, (x, y) in batch_iter:\n",
        "            input, target = x, y\n",
        "           \n",
        "            self.optimizer.zero_grad()  # zerograd the parameters\n",
        "            out = self.model(input)  # One forward pass\n",
        "            loss = self.criterion(out, target)  # Calculate loss\n",
        "            loss_value = loss.item()\n",
        "            train_losses.append(loss_value)\n",
        "            loss.backward()  # One backward pass\n",
        "            self.optimizer.step()  # Update the parameters\n",
        "\n",
        "            batch_iter.set_description(\n",
        "                f\"Training: (loss {loss_value:.4f})\"\n",
        "            )  # Update progressbar\n",
        "\n",
        "        self.training_loss.append(np.mean(train_losses))\n",
        "        self.learning_rate.append(self.optimizer.param_groups[0][\"lr\"])\n",
        "\n",
        "        batch_iter.close()\n",
        "\n",
        "  def _validate(self):\n",
        "\n",
        "\n",
        "        self.model.eval()  # Evaluation mode\n",
        "        valid_losses = []  # Accumulate the losses here\n",
        "        batch_iter = tqdm(\n",
        "            enumerate(self.validation_DataLoader),\n",
        "            \"Validation\",\n",
        "            total=len(self.validation_DataLoader),\n",
        "            leave=False,\n",
        "        )\n",
        "\n",
        "        for i, (x, y) in batch_iter:\n",
        "            input, target = x, y\n",
        "\n",
        "            with torch.no_grad():\n",
        "                out = self.model(input)\n",
        "                loss = self.criterion(out, target)\n",
        "                loss_value = loss.item()\n",
        "                valid_losses.append(loss_value)\n",
        "\n",
        "                batch_iter.set_description(f\"Validation: (loss \\\n",
        "                                                     {loss_value:.4f})\")\n",
        "\n",
        "        self.validation_loss.append(np.mean(valid_losses))\n",
        "\n",
        "        batch_iter.close()"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naqKw_ML9lVU"
      },
      "source": [
        "Functions for testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dto20MCv9jIy"
      },
      "source": [
        "########################Testing helpers start here##############################\n",
        "################################################################################\n",
        "\n",
        "# Function for updating\n",
        "def update_info(idx, length, epoch_loss, mode):\n",
        "\n",
        "  if length >= 250:\n",
        "    update_size = int(length/250)\n",
        "\n",
        "\n",
        "  if idx != 0:\n",
        "\n",
        "    finish_rate = idx/length * 100\n",
        "    print (\"\\r {} progress: {:.2f}% ...... loss: {:.4f}\".\n",
        "    format(mode, finish_rate, epoch_loss/idx), end=\"\", flush=True)\n",
        "\n",
        "# Testing Function\n",
        "def model_testing(model, loss_fn, dataloader, verbose=True):\n",
        "  Y_pred = []\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  epoch_loss = 0.0\n",
        "  test_size = 0\n",
        "  with torch.no_grad():\n",
        "    for i, (feature, target) in enumerate(dataloader):\n",
        "      feature = feature\n",
        "      target = target\n",
        "      outputs = model(feature) \n",
        "      test_size += target.size(0)\n",
        "      loss = criterion(outputs, target)\n",
        "      epoch_loss += loss.item()\n",
        "      idx = i\n",
        "      length = len(dataloader)\n",
        "      if verbose:\n",
        "        update_info(idx, length, epoch_loss, 'testing') \n",
        "  print('\\n\\n Loss of the network on the {} test images: {}'.format(test_size, \n",
        "                                                    epoch_loss/len(dataloader)))\n",
        "  return epoch_loss / len(dataloader)"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "finBHVR_-MN5"
      },
      "source": [
        "***Training***\n",
        "\n",
        "Loading the inputs and targets for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rhr8nZBrQIB6"
      },
      "source": [
        "# Create Root Directory for importing Dataset\n",
        "\n",
        "root = pathlib.Path.cwd() / \"drive/MyDrive/for_input\"\n",
        "\n",
        "# Input and target files\n",
        "inputs = get_filenames_of_path(root / \"input\")\n",
        "targets = get_filenames_of_path(root / \"target\")\n"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v5ExdGk3ZwD"
      },
      "source": [
        "*Transformation for inputs and targets*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4vM8XPUVRlf"
      },
      "source": [
        "# Call functions and classes for transforming the datasets\n",
        "transforms = ComposeDouble([  \n",
        "     FunctionWrapperDouble(resize,\n",
        "                          input=True,\n",
        "                          target=False,\n",
        "                          output_shape=(256, 256, 3)),\n",
        "    FunctionWrapperDouble(resize,\n",
        "                          input=False,\n",
        "                          target=True,\n",
        "                          output_shape=(256, 256),\n",
        "                          order=0,\n",
        "                          anti_aliasing=False,\n",
        "                          preserve_range=True),\n",
        "    AlbuSeg2d(albumentations.HorizontalFlip(p=0.5)),\n",
        "    FunctionWrapperDouble(create_dense_target, input=False, target=True),\n",
        "    FunctionWrapperDouble(np.moveaxis, input = True, \n",
        "                          target = False, source = -1, \n",
        "                          destination=0),\n",
        "    FunctionWrapperDouble(normalize_data)\n",
        "])"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_K3OdvkJNyE"
      },
      "source": [
        "# Split dataset into training set and validation set with 80:20\n",
        "train_size = 0.8  \n",
        "\n",
        "inputs_train, inputs_valid = train_test_split(\n",
        "    inputs, random_state=random_seed, train_size=train_size, shuffle=True)\n",
        "\n",
        "targets_train, targets_valid = train_test_split(\n",
        "    targets, random_state=random_seed, train_size=train_size, shuffle=True)\n",
        "\n",
        "\n",
        "# Training dataset\n",
        "dataset_train = Data_Augmentation(\n",
        "    inputs=inputs_train, targets=targets_train, transform=transforms)\n",
        "\n",
        "# Validation dataset\n",
        "dataset_valid = Data_Augmentation(\n",
        "    inputs=inputs_valid, targets=targets_valid, transform=transforms)\n",
        "\n",
        "# Training dataloader\n",
        "dataloader_training = DataLoader(dataset=dataset_train, \n",
        "                                 batch_size=2, \n",
        "                                 shuffle=True)\n",
        "\n",
        "# Validation dataloader\n",
        "dataloader_validation = DataLoader(dataset=dataset_valid, \n",
        "                                   batch_size=2, \n",
        "                                   shuffle=True)"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmOhqYwV3-Ni"
      },
      "source": [
        "*Printing shapes of input and target*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txR_RlL3SF0R",
        "outputId": "e931d4f8-7d44-49aa-bcea-29e78ca70878"
      },
      "source": [
        "# Input = x and target =y\n",
        "x, y = next(iter(dataloader_training))\n",
        "\n",
        "print(f'x = shape: {x.shape}; type: {x.dtype}')\n",
        "print(f'x = min: {x.min()}; max: {x.max()}')\n",
        "print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: FutureWarning: Non RGB image conversion is now deprecated. For RGBA images, please use rgb2gray(rgba2rgb(rgb)) instead. In version 0.19, a ValueError will be raised if input image last dimension length is not 3.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = shape: torch.Size([2, 3, 256, 256]); type: torch.float32\n",
            "x = min: 0.0; max: 1.0\n",
            "y = shape: torch.Size([2, 256, 256]); class: tensor([0]); type: torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lrw1ra92k7OB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ce160d5-2567-43b0-a417-54f664a08701"
      },
      "source": [
        "# Call the U-Net model for training\n",
        "# In_channels = 3, Out-channels = 2, Initialize_filters = 32\n",
        "model = UNet(3, 2, 32)\n",
        "\n",
        "# Function for initializing weight\n",
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        torch.nn.init.xavier_uniform(m.weight) # Initialize weight\n",
        "        m.bias.data.fill_(0.01)                # Initialize bias\n",
        "\n",
        "# Apply initial weights\n",
        "model.apply(init_weights)"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UNet(\n",
              "  (encoder_1): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "  )\n",
              "  (pool_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (encoder_2): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "  )\n",
              "  (pool_2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (encoder_3): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "  )\n",
              "  (pool_3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (encoder_4): Sequential(\n",
              "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "  )\n",
              "  (pool_4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (bottleneck): Sequential(\n",
              "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "  )\n",
              "  (upconv_4): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (decoder_4): Sequential(\n",
              "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "  )\n",
              "  (upconv_3): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (decoder_3): Sequential(\n",
              "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "  )\n",
              "  (upconv_2): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (decoder_2): Sequential(\n",
              "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "  )\n",
              "  (upconv_1): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (decoder_1): Sequential(\n",
              "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "  )\n",
              "  (conv): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dR7q1-9ZabjM",
        "outputId": "6dcbc40d-ce94-4498-e805-ff6c32699db5"
      },
      "source": [
        "####################################Training####################################\n",
        "################################################################################\n",
        "\n",
        "# Initialize criterion\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Initialize optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Call the trainer class\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    training_DataLoader=dataloader_training,\n",
        "    validation_DataLoader=dataloader_validation,\n",
        "    epochs=20,\n",
        "    epoch=0\n",
        ")\n",
        "\n",
        "# Start training\n",
        "training_losses, validation_losses, lr_rates = trainer.run_trainer()"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress:   0%|          | 0/20 [00:00<?, ?it/s]\n",
            "Training:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: FutureWarning: Non RGB image conversion is now deprecated. For RGBA images, please use rgb2gray(rgba2rgb(rgb)) instead. In version 0.19, a ValueError will be raised if input image last dimension length is not 3.\n",
            "\n",
            "Training: (loss 0.7520):   0%|          | 0/6 [00:05<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.7520):  17%|█▋        | 1/6 [00:05<00:27,  5.43s/it]\u001b[A\n",
            "Training: (loss 0.7524):  17%|█▋        | 1/6 [00:10<00:27,  5.43s/it]\u001b[A\n",
            "Training: (loss 0.7524):  33%|███▎      | 2/6 [00:10<00:21,  5.42s/it]\u001b[A\n",
            "Training: (loss 0.7479):  33%|███▎      | 2/6 [00:16<00:21,  5.42s/it]\u001b[A\n",
            "Training: (loss 0.7479):  50%|█████     | 3/6 [00:16<00:16,  5.40s/it]\u001b[A\n",
            "Training: (loss 0.7489):  50%|█████     | 3/6 [00:21<00:16,  5.40s/it]\u001b[A\n",
            "Training: (loss 0.7489):  67%|██████▋   | 4/6 [00:21<00:10,  5.40s/it]\u001b[A\n",
            "Training: (loss 0.7459):  67%|██████▋   | 4/6 [00:26<00:10,  5.40s/it]\u001b[A\n",
            "Training: (loss 0.7459):  83%|████████▎ | 5/6 [00:26<00:05,  5.38s/it]\u001b[A\n",
            "Training: (loss 0.7329):  83%|████████▎ | 5/6 [00:29<00:05,  5.38s/it]\u001b[A\n",
            "Training: (loss 0.7329): 100%|██████████| 6/6 [00:29<00:00,  4.47s/it]\u001b[A\n",
            "                                                                      \u001b[A\n",
            "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.7075):   0%|          | 0/2 [00:03<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.7075):  50%|█████     | 1/2 [00:03<00:03,  3.17s/it]\u001b[A\n",
            "Validation: (loss                                                      0.7061):  50%|█████     | 1/2 [00:04<00:03,  3.17s/it]\u001b[A\n",
            "Validation: (loss                                                      0.7061): 100%|██████████| 2/2 [00:04<00:00,  2.31s/it]\u001b[A\n",
            "Progress:   5%|▌         | 1/20 [00:34<10:57, 34.58s/it]\n",
            "Training:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.7406):   0%|          | 0/6 [00:05<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.7406):  17%|█▋        | 1/6 [00:05<00:27,  5.50s/it]\u001b[A\n",
            "Training: (loss 0.7410):  17%|█▋        | 1/6 [00:10<00:27,  5.50s/it]\u001b[A\n",
            "Training: (loss 0.7410):  33%|███▎      | 2/6 [00:10<00:21,  5.46s/it]\u001b[A\n",
            "Training: (loss 0.7278):  33%|███▎      | 2/6 [00:16<00:21,  5.46s/it]\u001b[A\n",
            "Training: (loss 0.7278):  50%|█████     | 3/6 [00:16<00:16,  5.48s/it]\u001b[A\n",
            "Training: (loss 0.7373):  50%|█████     | 3/6 [00:21<00:16,  5.48s/it]\u001b[A\n",
            "Training: (loss 0.7373):  67%|██████▋   | 4/6 [00:21<00:10,  5.44s/it]\u001b[A\n",
            "Training: (loss 0.7388):  67%|██████▋   | 4/6 [00:27<00:10,  5.44s/it]\u001b[A\n",
            "Training: (loss 0.7388):  83%|████████▎ | 5/6 [00:27<00:05,  5.43s/it]\u001b[A\n",
            "Training: (loss 0.7337):  83%|████████▎ | 5/6 [00:29<00:05,  5.43s/it]\u001b[A\n",
            "Training: (loss 0.7337): 100%|██████████| 6/6 [00:29<00:00,  4.52s/it]\u001b[A\n",
            "                                                                      \u001b[A\n",
            "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.7028):   0%|          | 0/2 [00:03<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.7028):  50%|█████     | 1/2 [00:03<00:03,  3.28s/it]\u001b[A\n",
            "Validation: (loss                                                      0.7028):  50%|█████     | 1/2 [00:04<00:03,  3.28s/it]\u001b[A\n",
            "Validation: (loss                                                      0.7028): 100%|██████████| 2/2 [00:04<00:00,  2.30s/it]\u001b[A\n",
            "Progress:  10%|█         | 2/20 [01:09<10:25, 34.76s/it]\n",
            "Training:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.7302):   0%|          | 0/6 [00:05<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.7302):  17%|█▋        | 1/6 [00:05<00:27,  5.45s/it]\u001b[A\n",
            "Training: (loss 0.7277):  17%|█▋        | 1/6 [00:10<00:27,  5.45s/it]\u001b[A\n",
            "Training: (loss 0.7277):  33%|███▎      | 2/6 [00:10<00:21,  5.43s/it]\u001b[A\n",
            "Training: (loss 0.7307):  33%|███▎      | 2/6 [00:16<00:21,  5.43s/it]\u001b[A\n",
            "Training: (loss 0.7307):  50%|█████     | 3/6 [00:16<00:16,  5.46s/it]\u001b[A\n",
            "Training: (loss 0.7264):  50%|█████     | 3/6 [00:21<00:16,  5.46s/it]\u001b[A\n",
            "Training: (loss 0.7264):  67%|██████▋   | 4/6 [00:21<00:11,  5.50s/it]\u001b[A\n",
            "Training: (loss 0.7276):  67%|██████▋   | 4/6 [00:27<00:11,  5.50s/it]\u001b[A\n",
            "Training: (loss 0.7276):  83%|████████▎ | 5/6 [00:27<00:05,  5.50s/it]\u001b[A\n",
            "Training: (loss 0.7145):  83%|████████▎ | 5/6 [00:30<00:05,  5.50s/it]\u001b[A\n",
            "Training: (loss 0.7145): 100%|██████████| 6/6 [00:30<00:00,  4.58s/it]\u001b[A\n",
            "                                                                      \u001b[A\n",
            "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.6988):   0%|          | 0/2 [00:03<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.6988):  50%|█████     | 1/2 [00:03<00:03,  3.30s/it]\u001b[A\n",
            "Validation: (loss                                                      0.7036):  50%|█████     | 1/2 [00:05<00:03,  3.30s/it]\u001b[A\n",
            "Validation: (loss                                                      0.7036): 100%|██████████| 2/2 [00:05<00:00,  2.37s/it]\u001b[A\n",
            "Progress:  15%|█▌        | 3/20 [01:44<09:55, 35.00s/it]\n",
            "Training:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.7186):   0%|          | 0/6 [00:05<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.7186):  17%|█▋        | 1/6 [00:05<00:27,  5.49s/it]\u001b[A\n",
            "Training: (loss 0.7176):  17%|█▋        | 1/6 [00:10<00:27,  5.49s/it]\u001b[A\n",
            "Training: (loss 0.7176):  33%|███▎      | 2/6 [00:10<00:21,  5.50s/it]\u001b[A\n",
            "Training: (loss 0.7184):  33%|███▎      | 2/6 [00:16<00:21,  5.50s/it]\u001b[A\n",
            "Training: (loss 0.7184):  50%|█████     | 3/6 [00:16<00:16,  5.50s/it]\u001b[A\n",
            "Training: (loss 0.7146):  50%|█████     | 3/6 [00:22<00:16,  5.50s/it]\u001b[A\n",
            "Training: (loss 0.7146):  67%|██████▋   | 4/6 [00:22<00:11,  5.55s/it]\u001b[A\n",
            "Training: (loss 0.7182):  67%|██████▋   | 4/6 [00:27<00:11,  5.55s/it]\u001b[A\n",
            "Training: (loss 0.7182):  83%|████████▎ | 5/6 [00:27<00:05,  5.54s/it]\u001b[A\n",
            "Training: (loss 0.7157):  83%|████████▎ | 5/6 [00:30<00:05,  5.54s/it]\u001b[A\n",
            "Training: (loss 0.7157): 100%|██████████| 6/6 [00:30<00:00,  4.63s/it]\u001b[A\n",
            "                                                                      \u001b[A\n",
            "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.7021):   0%|          | 0/2 [00:03<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.7021):  50%|█████     | 1/2 [00:03<00:03,  3.34s/it]\u001b[A\n",
            "Validation: (loss                                                      0.6952):  50%|█████     | 1/2 [00:04<00:03,  3.34s/it]\u001b[A\n",
            "Validation: (loss                                                      0.6952): 100%|██████████| 2/2 [00:04<00:00,  2.34s/it]\u001b[A\n",
            "Progress:  20%|██        | 4/20 [02:20<09:23, 35.22s/it]\n",
            "Training:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.7130):   0%|          | 0/6 [00:05<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.7130):  17%|█▋        | 1/6 [00:05<00:27,  5.53s/it]\u001b[A\n",
            "Training: (loss 0.7061):  17%|█▋        | 1/6 [00:11<00:27,  5.53s/it]\u001b[A\n",
            "Training: (loss 0.7061):  33%|███▎      | 2/6 [00:11<00:22,  5.54s/it]\u001b[A\n",
            "Training: (loss 0.7084):  33%|███▎      | 2/6 [00:16<00:22,  5.54s/it]\u001b[A\n",
            "Training: (loss 0.7084):  50%|█████     | 3/6 [00:16<00:16,  5.53s/it]\u001b[A\n",
            "Training: (loss 0.7088):  50%|█████     | 3/6 [00:22<00:16,  5.53s/it]\u001b[A\n",
            "Training: (loss 0.7088):  67%|██████▋   | 4/6 [00:22<00:11,  5.51s/it]\u001b[A\n",
            "Training: (loss 0.7046):  67%|██████▋   | 4/6 [00:27<00:11,  5.51s/it]\u001b[A\n",
            "Training: (loss 0.7046):  83%|████████▎ | 5/6 [00:27<00:05,  5.52s/it]\u001b[A\n",
            "Training: (loss 0.6988):  83%|████████▎ | 5/6 [00:30<00:05,  5.52s/it]\u001b[A\n",
            "Training: (loss 0.6988): 100%|██████████| 6/6 [00:30<00:00,  4.60s/it]\u001b[A\n",
            "                                                                      \u001b[A\n",
            "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.6887):   0%|          | 0/2 [00:03<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.6887):  50%|█████     | 1/2 [00:03<00:03,  3.19s/it]\u001b[A\n",
            "Validation: (loss                                                      0.7135):  50%|█████     | 1/2 [00:04<00:03,  3.19s/it]\u001b[A\n",
            "Validation: (loss                                                      0.7135): 100%|██████████| 2/2 [00:04<00:00,  2.33s/it]\u001b[A\n",
            "Progress:  25%|██▌       | 5/20 [02:55<08:49, 35.28s/it]\n",
            "Training:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.7038):   0%|          | 0/6 [00:05<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.7038):  17%|█▋        | 1/6 [00:05<00:27,  5.46s/it]\u001b[A\n",
            "Training: (loss 0.6966):  17%|█▋        | 1/6 [00:10<00:27,  5.46s/it]\u001b[A\n",
            "Training: (loss 0.6966):  33%|███▎      | 2/6 [00:10<00:21,  5.39s/it]\u001b[A\n",
            "Training: (loss 0.7021):  33%|███▎      | 2/6 [00:16<00:21,  5.39s/it]\u001b[A\n",
            "Training: (loss 0.7021):  50%|█████     | 3/6 [00:16<00:16,  5.37s/it]\u001b[A\n",
            "Training: (loss 0.6943):  50%|█████     | 3/6 [00:21<00:16,  5.37s/it]\u001b[A\n",
            "Training: (loss 0.6943):  67%|██████▋   | 4/6 [00:21<00:10,  5.41s/it]\u001b[A\n",
            "Training: (loss 0.6937):  67%|██████▋   | 4/6 [00:27<00:10,  5.41s/it]\u001b[A\n",
            "Training: (loss 0.6937):  83%|████████▎ | 5/6 [00:27<00:05,  5.43s/it]\u001b[A\n",
            "Training: (loss 0.6991):  83%|████████▎ | 5/6 [00:29<00:05,  5.43s/it]\u001b[A\n",
            "Training: (loss 0.6991): 100%|██████████| 6/6 [00:29<00:00,  4.53s/it]\u001b[A\n",
            "                                                                      \u001b[A\n",
            "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.6977):   0%|          | 0/2 [00:03<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.6977):  50%|█████     | 1/2 [00:03<00:03,  3.27s/it]\u001b[A\n",
            "Validation: (loss                                                      0.6837):  50%|█████     | 1/2 [00:04<00:03,  3.27s/it]\u001b[A\n",
            "Validation: (loss                                                      0.6837): 100%|██████████| 2/2 [00:04<00:00,  2.30s/it]\u001b[A\n",
            "Progress:  30%|███       | 6/20 [03:30<08:11, 35.11s/it]\n",
            "Training:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.6925):   0%|          | 0/6 [00:05<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.6925):  17%|█▋        | 1/6 [00:05<00:27,  5.46s/it]\u001b[A\n",
            "Training: (loss 0.6893):  17%|█▋        | 1/6 [00:10<00:27,  5.46s/it]\u001b[A\n",
            "Training: (loss 0.6893):  33%|███▎      | 2/6 [00:10<00:21,  5.48s/it]\u001b[A\n",
            "Training: (loss 0.6884):  33%|███▎      | 2/6 [00:16<00:21,  5.48s/it]\u001b[A\n",
            "Training: (loss 0.6884):  50%|█████     | 3/6 [00:16<00:16,  5.46s/it]\u001b[A\n",
            "Training: (loss 0.6906):  50%|█████     | 3/6 [00:21<00:16,  5.46s/it]\u001b[A\n",
            "Training: (loss 0.6906):  67%|██████▋   | 4/6 [00:21<00:10,  5.46s/it]\u001b[A\n",
            "Training: (loss 0.6867):  67%|██████▋   | 4/6 [00:27<00:10,  5.46s/it]\u001b[A\n",
            "Training: (loss 0.6867):  83%|████████▎ | 5/6 [00:27<00:05,  5.45s/it]\u001b[A\n",
            "Training: (loss 0.6824):  83%|████████▎ | 5/6 [00:30<00:05,  5.45s/it]\u001b[A\n",
            "Training: (loss 0.6824): 100%|██████████| 6/6 [00:30<00:00,  4.53s/it]\u001b[A\n",
            "                                                                      \u001b[A\n",
            "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.6932):   0%|          | 0/2 [00:03<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.6932):  50%|█████     | 1/2 [00:03<00:03,  3.22s/it]\u001b[A\n",
            "Validation: (loss                                                      0.6777):  50%|█████     | 1/2 [00:04<00:03,  3.22s/it]\u001b[A\n",
            "Validation: (loss                                                      0.6777): 100%|██████████| 2/2 [00:04<00:00,  2.27s/it]\u001b[A\n",
            "Progress:  35%|███▌      | 7/20 [04:05<07:35, 35.04s/it]\n",
            "Training:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.6823):   0%|          | 0/6 [00:05<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.6823):  17%|█▋        | 1/6 [00:05<00:27,  5.44s/it]\u001b[A\n",
            "Training: (loss 0.6809):  17%|█▋        | 1/6 [00:10<00:27,  5.44s/it]\u001b[A\n",
            "Training: (loss 0.6809):  33%|███▎      | 2/6 [00:10<00:21,  5.44s/it]\u001b[A\n",
            "Training: (loss 0.6810):  33%|███▎      | 2/6 [00:16<00:21,  5.44s/it]\u001b[A\n",
            "Training: (loss 0.6810):  50%|█████     | 3/6 [00:16<00:16,  5.43s/it]\u001b[A\n",
            "Training: (loss 0.6770):  50%|█████     | 3/6 [00:21<00:16,  5.43s/it]\u001b[A\n",
            "Training: (loss 0.6770):  67%|██████▋   | 4/6 [00:21<00:10,  5.42s/it]\u001b[A\n",
            "Training: (loss 0.6766):  67%|██████▋   | 4/6 [00:27<00:10,  5.42s/it]\u001b[A\n",
            "Training: (loss 0.6766):  83%|████████▎ | 5/6 [00:27<00:05,  5.43s/it]\u001b[A\n",
            "Training: (loss 0.6798):  83%|████████▎ | 5/6 [00:29<00:05,  5.43s/it]\u001b[A\n",
            "Training: (loss 0.6798): 100%|██████████| 6/6 [00:29<00:00,  4.51s/it]\u001b[A\n",
            "                                                                      \u001b[A\n",
            "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.6708):   0%|          | 0/2 [00:03<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.6708):  50%|█████     | 1/2 [00:03<00:03,  3.16s/it]\u001b[A\n",
            "Validation: (loss                                                      0.7022):  50%|█████     | 1/2 [00:04<00:03,  3.16s/it]\u001b[A\n",
            "Validation: (loss                                                      0.7022): 100%|██████████| 2/2 [00:04<00:00,  2.29s/it]\u001b[A\n",
            "Progress:  40%|████      | 8/20 [04:40<06:59, 34.95s/it]\n",
            "Training:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.6720):   0%|          | 0/6 [00:05<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.6720):  17%|█▋        | 1/6 [00:05<00:26,  5.37s/it]\u001b[A\n",
            "Training: (loss 0.6696):  17%|█▋        | 1/6 [00:10<00:26,  5.37s/it]\u001b[A\n",
            "Training: (loss 0.6696):  33%|███▎      | 2/6 [00:10<00:21,  5.40s/it]\u001b[A\n",
            "Training: (loss 0.6669):  33%|███▎      | 2/6 [00:16<00:21,  5.40s/it]\u001b[A\n",
            "Training: (loss 0.6669):  50%|█████     | 3/6 [00:16<00:16,  5.45s/it]\u001b[A\n",
            "Training: (loss 0.6687):  50%|█████     | 3/6 [00:21<00:16,  5.45s/it]\u001b[A\n",
            "Training: (loss 0.6687):  67%|██████▋   | 4/6 [00:21<00:10,  5.48s/it]\u001b[A\n",
            "Training: (loss 0.6741):  67%|██████▋   | 4/6 [00:27<00:10,  5.48s/it]\u001b[A\n",
            "Training: (loss 0.6741):  83%|████████▎ | 5/6 [00:27<00:05,  5.51s/it]\u001b[A\n",
            "Training: (loss 0.6712):  83%|████████▎ | 5/6 [00:30<00:05,  5.51s/it]\u001b[A\n",
            "Training: (loss 0.6712): 100%|██████████| 6/6 [00:30<00:00,  4.61s/it]\u001b[A\n",
            "                                                                      \u001b[A\n",
            "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.6589):   0%|          | 0/2 [00:03<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.6589):  50%|█████     | 1/2 [00:03<00:03,  3.19s/it]\u001b[A\n",
            "Validation: (loss                                                      0.6929):  50%|█████     | 1/2 [00:04<00:03,  3.19s/it]\u001b[A\n",
            "Validation: (loss                                                      0.6929): 100%|██████████| 2/2 [00:04<00:00,  2.30s/it]\u001b[A\n",
            "Progress:  45%|████▌     | 9/20 [05:15<06:25, 35.01s/it]\n",
            "Training:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.6639):   0%|          | 0/6 [00:05<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.6639):  17%|█▋        | 1/6 [00:05<00:27,  5.46s/it]\u001b[A\n",
            "Training: (loss 0.6678):  17%|█▋        | 1/6 [00:10<00:27,  5.46s/it]\u001b[A\n",
            "Training: (loss 0.6678):  33%|███▎      | 2/6 [00:10<00:21,  5.43s/it]\u001b[A\n",
            "Training: (loss 0.6597):  33%|███▎      | 2/6 [00:16<00:21,  5.43s/it]\u001b[A\n",
            "Training: (loss 0.6597):  50%|█████     | 3/6 [00:16<00:16,  5.43s/it]\u001b[A\n",
            "Training: (loss 0.6649):  50%|█████     | 3/6 [00:21<00:16,  5.43s/it]\u001b[A\n",
            "Training: (loss 0.6649):  67%|██████▋   | 4/6 [00:21<00:10,  5.41s/it]\u001b[A\n",
            "Training: (loss 0.6582):  67%|██████▋   | 4/6 [00:27<00:10,  5.41s/it]\u001b[A\n",
            "Training: (loss 0.6582):  83%|████████▎ | 5/6 [00:27<00:05,  5.40s/it]\u001b[A\n",
            "Training: (loss 0.6623):  83%|████████▎ | 5/6 [00:29<00:05,  5.40s/it]\u001b[A\n",
            "Training: (loss 0.6623): 100%|██████████| 6/6 [00:29<00:00,  4.51s/it]\u001b[A\n",
            "                                                                      \u001b[A\n",
            "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.6466):   0%|          | 0/2 [00:03<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.6466):  50%|█████     | 1/2 [00:03<00:03,  3.19s/it]\u001b[A\n",
            "Validation: (loss                                                      0.6838):  50%|█████     | 1/2 [00:04<00:03,  3.19s/it]\u001b[A\n",
            "Validation: (loss                                                      0.6838): 100%|██████████| 2/2 [00:04<00:00,  2.29s/it]\u001b[A\n",
            "Progress:  50%|█████     | 10/20 [05:50<05:49, 34.93s/it]\n",
            "Training:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.6585):   0%|          | 0/6 [00:05<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.6585):  17%|█▋        | 1/6 [00:05<00:27,  5.41s/it]\u001b[A\n",
            "Training: (loss 0.6621):  17%|█▋        | 1/6 [00:10<00:27,  5.41s/it]\u001b[A\n",
            "Training: (loss 0.6621):  33%|███▎      | 2/6 [00:10<00:21,  5.46s/it]\u001b[A\n",
            "Training: (loss 0.6528):  33%|███▎      | 2/6 [00:16<00:21,  5.46s/it]\u001b[A\n",
            "Training: (loss 0.6528):  50%|█████     | 3/6 [00:16<00:16,  5.48s/it]\u001b[A\n",
            "Training: (loss 0.6589):  50%|█████     | 3/6 [00:21<00:16,  5.48s/it]\u001b[A\n",
            "Training: (loss 0.6589):  67%|██████▋   | 4/6 [00:21<00:10,  5.45s/it]\u001b[A\n",
            "Training: (loss 0.6574):  67%|██████▋   | 4/6 [00:27<00:10,  5.45s/it]\u001b[A\n",
            "Training: (loss 0.6574):  83%|████████▎ | 5/6 [00:27<00:05,  5.43s/it]\u001b[A\n",
            "Training: (loss 0.6560):  83%|████████▎ | 5/6 [00:29<00:05,  5.43s/it]\u001b[A\n",
            "Training: (loss 0.6560): 100%|██████████| 6/6 [00:29<00:00,  4.52s/it]\u001b[A\n",
            "                                                                      \u001b[A\n",
            "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.6371):   0%|          | 0/2 [00:03<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.6371):  50%|█████     | 1/2 [00:03<00:03,  3.17s/it]\u001b[A\n",
            "Validation: (loss                                                      0.6733):  50%|█████     | 1/2 [00:04<00:03,  3.17s/it]\u001b[A\n",
            "Validation: (loss                                                      0.6733): 100%|██████████| 2/2 [00:04<00:00,  2.29s/it]\u001b[A\n",
            "Progress:  55%|█████▌    | 11/20 [06:24<05:14, 34.91s/it]\n",
            "Training:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.6532):   0%|          | 0/6 [00:05<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.6532):  17%|█▋        | 1/6 [00:05<00:26,  5.38s/it]\u001b[A\n",
            "Training: (loss 0.6549):  17%|█▋        | 1/6 [00:10<00:26,  5.38s/it]\u001b[A\n",
            "Training: (loss 0.6549):  33%|███▎      | 2/6 [00:10<00:21,  5.42s/it]\u001b[A\n",
            "Training: (loss 0.6508):  33%|███▎      | 2/6 [00:16<00:21,  5.42s/it]\u001b[A\n",
            "Training: (loss 0.6508):  50%|█████     | 3/6 [00:16<00:16,  5.41s/it]\u001b[A\n",
            "Training: (loss 0.6443):  50%|█████     | 3/6 [00:21<00:16,  5.41s/it]\u001b[A\n",
            "Training: (loss 0.6443):  67%|██████▋   | 4/6 [00:21<00:10,  5.35s/it]\u001b[A\n",
            "Training: (loss 0.6488):  67%|██████▋   | 4/6 [00:26<00:10,  5.35s/it]\u001b[A\n",
            "Training: (loss 0.6488):  83%|████████▎ | 5/6 [00:26<00:05,  5.32s/it]\u001b[A\n",
            "Training: (loss 0.6506):  83%|████████▎ | 5/6 [00:29<00:05,  5.32s/it]\u001b[A\n",
            "Training: (loss 0.6506): 100%|██████████| 6/6 [00:29<00:00,  4.43s/it]\u001b[A\n",
            "                                                                      \u001b[A\n",
            "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.6455):   0%|          | 0/2 [00:03<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.6455):  50%|█████     | 1/2 [00:03<00:03,  3.07s/it]\u001b[A\n",
            "Validation: (loss                                                      0.6296):  50%|█████     | 1/2 [00:04<00:03,  3.07s/it]\u001b[A\n",
            "Validation: (loss                                                      0.6296): 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]\u001b[A\n",
            "Progress:  60%|██████    | 12/20 [06:58<04:37, 34.66s/it]\n",
            "Training:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.6480):   0%|          | 0/6 [00:05<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.6480):  17%|█▋        | 1/6 [00:05<00:26,  5.25s/it]\u001b[A\n",
            "Training: (loss 0.6473):  17%|█▋        | 1/6 [00:10<00:26,  5.25s/it]\u001b[A\n",
            "Training: (loss 0.6473):  33%|███▎      | 2/6 [00:10<00:21,  5.28s/it]\u001b[A\n",
            "Training: (loss 0.6387):  33%|███▎      | 2/6 [00:15<00:21,  5.28s/it]\u001b[A\n",
            "Training: (loss 0.6387):  50%|█████     | 3/6 [00:15<00:15,  5.27s/it]\u001b[A\n",
            "Training: (loss 0.6346):  50%|█████     | 3/6 [00:21<00:15,  5.27s/it]\u001b[A\n",
            "Training: (loss 0.6346):  67%|██████▋   | 4/6 [00:21<00:10,  5.25s/it]\u001b[A\n",
            "Training: (loss 0.6355):  67%|██████▋   | 4/6 [00:26<00:10,  5.25s/it]\u001b[A\n",
            "Training: (loss 0.6355):  83%|████████▎ | 5/6 [00:26<00:05,  5.28s/it]\u001b[A\n",
            "Training: (loss 0.6413):  83%|████████▎ | 5/6 [00:29<00:05,  5.28s/it]\u001b[A\n",
            "Training: (loss 0.6413): 100%|██████████| 6/6 [00:29<00:00,  4.41s/it]\u001b[A\n",
            "                                                                      \u001b[A\n",
            "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.6405):   0%|          | 0/2 [00:03<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.6405):  50%|█████     | 1/2 [00:03<00:03,  3.12s/it]\u001b[A\n",
            "Validation: (loss                                                      0.6248):  50%|█████     | 1/2 [00:04<00:03,  3.12s/it]\u001b[A\n",
            "Validation: (loss                                                      0.6248): 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]\u001b[A\n",
            "Progress:  65%|██████▌   | 13/20 [07:32<04:00, 34.40s/it]\n",
            "Training:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.6327):   0%|          | 0/6 [00:05<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.6327):  17%|█▋        | 1/6 [00:05<00:26,  5.24s/it]\u001b[A\n",
            "Training: (loss 0.6296):  17%|█▋        | 1/6 [00:10<00:26,  5.24s/it]\u001b[A\n",
            "Training: (loss 0.6296):  33%|███▎      | 2/6 [00:10<00:21,  5.28s/it]\u001b[A\n",
            "Training: (loss 0.6385):  33%|███▎      | 2/6 [00:15<00:21,  5.28s/it]\u001b[A\n",
            "Training: (loss 0.6385):  50%|█████     | 3/6 [00:15<00:15,  5.26s/it]\u001b[A\n",
            "Training: (loss 0.6346):  50%|█████     | 3/6 [00:21<00:15,  5.26s/it]\u001b[A\n",
            "Training: (loss 0.6346):  67%|██████▋   | 4/6 [00:21<00:10,  5.28s/it]\u001b[A\n",
            "Training: (loss 0.6374):  67%|██████▋   | 4/6 [00:26<00:10,  5.28s/it]\u001b[A\n",
            "Training: (loss 0.6374):  83%|████████▎ | 5/6 [00:26<00:05,  5.28s/it]\u001b[A\n",
            "Training: (loss 0.6337):  83%|████████▎ | 5/6 [00:29<00:05,  5.28s/it]\u001b[A\n",
            "Training: (loss 0.6337): 100%|██████████| 6/6 [00:29<00:00,  4.39s/it]\u001b[A\n",
            "                                                                      \u001b[A\n",
            "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.6053):   0%|          | 0/2 [00:03<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.6053):  50%|█████     | 1/2 [00:03<00:03,  3.06s/it]\u001b[A\n",
            "Validation: (loss                                                      0.6481):  50%|█████     | 1/2 [00:04<00:03,  3.06s/it]\u001b[A\n",
            "Validation: (loss                                                      0.6481): 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]\u001b[A\n",
            "Progress:  70%|███████   | 14/20 [08:06<03:25, 34.20s/it]\n",
            "Training:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.6326):   0%|          | 0/6 [00:05<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.6326):  17%|█▋        | 1/6 [00:05<00:26,  5.22s/it]\u001b[A\n",
            "Training: (loss 0.6219):  17%|█▋        | 1/6 [00:10<00:26,  5.22s/it]\u001b[A\n",
            "Training: (loss 0.6219):  33%|███▎      | 2/6 [00:10<00:20,  5.25s/it]\u001b[A\n",
            "Training: (loss 0.6224):  33%|███▎      | 2/6 [00:15<00:20,  5.25s/it]\u001b[A\n",
            "Training: (loss 0.6224):  50%|█████     | 3/6 [00:15<00:15,  5.25s/it]\u001b[A\n",
            "Training: (loss 0.6279):  50%|█████     | 3/6 [00:21<00:15,  5.25s/it]\u001b[A\n",
            "Training: (loss 0.6279):  67%|██████▋   | 4/6 [00:21<00:10,  5.26s/it]\u001b[A\n",
            "Training: (loss 0.6296):  67%|██████▋   | 4/6 [00:26<00:10,  5.26s/it]\u001b[A\n",
            "Training: (loss 0.6296):  83%|████████▎ | 5/6 [00:26<00:05,  5.27s/it]\u001b[A\n",
            "Training: (loss 0.6271):  83%|████████▎ | 5/6 [00:28<00:05,  5.27s/it]\u001b[A\n",
            "Training: (loss 0.6271): 100%|██████████| 6/6 [00:28<00:00,  4.39s/it]\u001b[A\n",
            "                                                                      \u001b[A\n",
            "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.6171):   0%|          | 0/2 [00:03<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.6171):  50%|█████     | 1/2 [00:03<00:03,  3.09s/it]\u001b[A\n",
            "Validation: (loss                                                      0.5969):  50%|█████     | 1/2 [00:04<00:03,  3.09s/it]\u001b[A\n",
            "Validation: (loss                                                      0.5969): 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]\u001b[A\n",
            "Progress:  75%|███████▌  | 15/20 [08:40<02:50, 34.03s/it]\n",
            "Training:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.6177):   0%|          | 0/6 [00:05<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.6177):  17%|█▋        | 1/6 [00:05<00:26,  5.29s/it]\u001b[A\n",
            "Training: (loss 0.6144):  17%|█▋        | 1/6 [00:10<00:26,  5.29s/it]\u001b[A\n",
            "Training: (loss 0.6144):  33%|███▎      | 2/6 [00:10<00:21,  5.27s/it]\u001b[A\n",
            "Training: (loss 0.6152):  33%|███▎      | 2/6 [00:15<00:21,  5.27s/it]\u001b[A\n",
            "Training: (loss 0.6152):  50%|█████     | 3/6 [00:15<00:15,  5.27s/it]\u001b[A\n",
            "Training: (loss 0.6117):  50%|█████     | 3/6 [00:21<00:15,  5.27s/it]\u001b[A\n",
            "Training: (loss 0.6117):  67%|██████▋   | 4/6 [00:21<00:10,  5.27s/it]\u001b[A\n",
            "Training: (loss 0.6228):  67%|██████▋   | 4/6 [00:26<00:10,  5.27s/it]\u001b[A\n",
            "Training: (loss 0.6228):  83%|████████▎ | 5/6 [00:26<00:05,  5.29s/it]\u001b[A\n",
            "Training: (loss 0.6201):  83%|████████▎ | 5/6 [00:29<00:05,  5.29s/it]\u001b[A\n",
            "Training: (loss 0.6201): 100%|██████████| 6/6 [00:29<00:00,  4.41s/it]\u001b[A\n",
            "                                                                      \u001b[A\n",
            "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.6125):   0%|          | 0/2 [00:03<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.6125):  50%|█████     | 1/2 [00:03<00:03,  3.13s/it]\u001b[A\n",
            "Validation: (loss                                                      0.5886):  50%|█████     | 1/2 [00:04<00:03,  3.13s/it]\u001b[A\n",
            "Validation: (loss                                                      0.5886): 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]\u001b[A\n",
            "Progress:  80%|████████  | 16/20 [09:13<02:15, 33.97s/it]\n",
            "Training:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.6175):   0%|          | 0/6 [00:05<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.6175):  17%|█▋        | 1/6 [00:05<00:26,  5.31s/it]\u001b[A\n",
            "Training: (loss 0.6096):  17%|█▋        | 1/6 [00:10<00:26,  5.31s/it]\u001b[A\n",
            "Training: (loss 0.6096):  33%|███▎      | 2/6 [00:10<00:21,  5.28s/it]\u001b[A\n",
            "Training: (loss 0.6185):  33%|███▎      | 2/6 [00:15<00:21,  5.28s/it]\u001b[A\n",
            "Training: (loss 0.6185):  50%|█████     | 3/6 [00:15<00:15,  5.30s/it]\u001b[A\n",
            "Training: (loss 0.6175):  50%|█████     | 3/6 [00:21<00:15,  5.30s/it]\u001b[A\n",
            "Training: (loss 0.6175):  67%|██████▋   | 4/6 [00:21<00:10,  5.29s/it]\u001b[A\n",
            "Training: (loss 0.6030):  67%|██████▋   | 4/6 [00:26<00:10,  5.29s/it]\u001b[A\n",
            "Training: (loss 0.6030):  83%|████████▎ | 5/6 [00:26<00:05,  5.28s/it]\u001b[A\n",
            "Training: (loss 0.6149):  83%|████████▎ | 5/6 [00:29<00:05,  5.28s/it]\u001b[A\n",
            "Training: (loss 0.6149): 100%|██████████| 6/6 [00:29<00:00,  4.38s/it]\u001b[A\n",
            "                                                                      \u001b[A\n",
            "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.5795):   0%|          | 0/2 [00:03<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.5795):  50%|█████     | 1/2 [00:03<00:03,  3.08s/it]\u001b[A\n",
            "Validation: (loss                                                      0.6280):  50%|█████     | 1/2 [00:04<00:03,  3.08s/it]\u001b[A\n",
            "Validation: (loss                                                      0.6280): 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]\u001b[A\n",
            "Progress:  85%|████████▌ | 17/20 [09:47<01:41, 33.91s/it]\n",
            "Training:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.6035):   0%|          | 0/6 [00:05<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.6035):  17%|█▋        | 1/6 [00:05<00:26,  5.25s/it]\u001b[A\n",
            "Training: (loss 0.6125):  17%|█▋        | 1/6 [00:10<00:26,  5.25s/it]\u001b[A\n",
            "Training: (loss 0.6125):  33%|███▎      | 2/6 [00:10<00:21,  5.26s/it]\u001b[A\n",
            "Training: (loss 0.6015):  33%|███▎      | 2/6 [00:15<00:21,  5.26s/it]\u001b[A\n",
            "Training: (loss 0.6015):  50%|█████     | 3/6 [00:15<00:15,  5.27s/it]\u001b[A\n",
            "Training: (loss 0.5975):  50%|█████     | 3/6 [00:21<00:15,  5.27s/it]\u001b[A\n",
            "Training: (loss 0.5975):  67%|██████▋   | 4/6 [00:21<00:10,  5.27s/it]\u001b[A\n",
            "Training: (loss 0.5987):  67%|██████▋   | 4/6 [00:26<00:10,  5.27s/it]\u001b[A\n",
            "Training: (loss 0.5987):  83%|████████▎ | 5/6 [00:26<00:05,  5.24s/it]\u001b[A\n",
            "Training: (loss 0.6042):  83%|████████▎ | 5/6 [00:28<00:05,  5.24s/it]\u001b[A\n",
            "Training: (loss 0.6042): 100%|██████████| 6/6 [00:28<00:00,  4.36s/it]\u001b[A\n",
            "                                                                      \u001b[A\n",
            "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.5996):   0%|          | 0/2 [00:03<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.5996):  50%|█████     | 1/2 [00:03<00:03,  3.10s/it]\u001b[A\n",
            "Validation: (loss                                                      0.5737):  50%|█████     | 1/2 [00:04<00:03,  3.10s/it]\u001b[A\n",
            "Validation: (loss                                                      0.5737): 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]\u001b[A\n",
            "Progress:  90%|█████████ | 18/20 [10:21<01:07, 33.81s/it]\n",
            "Training:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.5967):   0%|          | 0/6 [00:05<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.5967):  17%|█▋        | 1/6 [00:05<00:26,  5.33s/it]\u001b[A\n",
            "Training: (loss 0.5921):  17%|█▋        | 1/6 [00:10<00:26,  5.33s/it]\u001b[A\n",
            "Training: (loss 0.5921):  33%|███▎      | 2/6 [00:10<00:21,  5.28s/it]\u001b[A\n",
            "Training: (loss 0.5940):  33%|███▎      | 2/6 [00:15<00:21,  5.28s/it]\u001b[A\n",
            "Training: (loss 0.5940):  50%|█████     | 3/6 [00:15<00:15,  5.24s/it]\u001b[A\n",
            "Training: (loss 0.6017):  50%|█████     | 3/6 [00:21<00:15,  5.24s/it]\u001b[A\n",
            "Training: (loss 0.6017):  67%|██████▋   | 4/6 [00:21<00:10,  5.25s/it]\u001b[A\n",
            "Training: (loss 0.5999):  67%|██████▋   | 4/6 [00:26<00:10,  5.25s/it]\u001b[A\n",
            "Training: (loss 0.5999):  83%|████████▎ | 5/6 [00:26<00:05,  5.25s/it]\u001b[A\n",
            "Training: (loss 0.6053):  83%|████████▎ | 5/6 [00:28<00:05,  5.25s/it]\u001b[A\n",
            "Training: (loss 0.6053): 100%|██████████| 6/6 [00:28<00:00,  4.36s/it]\u001b[A\n",
            "                                                                      \u001b[A\n",
            "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.5637):   0%|          | 0/2 [00:03<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.5637):  50%|█████     | 1/2 [00:03<00:03,  3.03s/it]\u001b[A\n",
            "Validation: (loss                                                      0.6123):  50%|█████     | 1/2 [00:04<00:03,  3.03s/it]\u001b[A\n",
            "Validation: (loss                                                      0.6123): 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]\u001b[A\n",
            "Progress:  95%|█████████▌| 19/20 [10:54<00:33, 33.75s/it]\n",
            "Training:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.5897):   0%|          | 0/6 [00:05<?, ?it/s]\u001b[A\n",
            "Training: (loss 0.5897):  17%|█▋        | 1/6 [00:05<00:26,  5.25s/it]\u001b[A\n",
            "Training: (loss 0.6019):  17%|█▋        | 1/6 [00:10<00:26,  5.25s/it]\u001b[A\n",
            "Training: (loss 0.6019):  33%|███▎      | 2/6 [00:10<00:21,  5.25s/it]\u001b[A\n",
            "Training: (loss 0.5983):  33%|███▎      | 2/6 [00:15<00:21,  5.25s/it]\u001b[A\n",
            "Training: (loss 0.5983):  50%|█████     | 3/6 [00:15<00:15,  5.26s/it]\u001b[A\n",
            "Training: (loss 0.5927):  50%|█████     | 3/6 [00:20<00:15,  5.26s/it]\u001b[A\n",
            "Training: (loss 0.5927):  67%|██████▋   | 4/6 [00:20<00:10,  5.22s/it]\u001b[A\n",
            "Training: (loss 0.5978):  67%|██████▋   | 4/6 [00:26<00:10,  5.22s/it]\u001b[A\n",
            "Training: (loss 0.5978):  83%|████████▎ | 5/6 [00:26<00:05,  5.24s/it]\u001b[A\n",
            "Training: (loss 0.5941):  83%|████████▎ | 5/6 [00:28<00:05,  5.24s/it]\u001b[A\n",
            "Training: (loss 0.5941): 100%|██████████| 6/6 [00:28<00:00,  4.36s/it]\u001b[A\n",
            "                                                                      \u001b[A\n",
            "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.5435):   0%|          | 0/2 [00:03<?, ?it/s]\u001b[A\n",
            "Validation: (loss                                                      0.5435):  50%|█████     | 1/2 [00:03<00:03,  3.05s/it]\u001b[A\n",
            "Validation: (loss                                                      0.6044):  50%|█████     | 1/2 [00:04<00:03,  3.05s/it]\u001b[A\n",
            "Validation: (loss                                                      0.6044): 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]\u001b[A\n",
            "Progress: 100%|██████████| 20/20 [11:28<00:00, 34.43s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "dDj8miqF3pcg",
        "outputId": "4b57a0e4-f919-451e-966a-b944c989f490"
      },
      "source": [
        "plt.plot(training_losses, label = \"Training Losses\")\n",
        "plt.plot(validation_losses, label = \"Validation Losses\")\n",
        "\n",
        "# X-axis\n",
        "plt.xlabel('Epochs')\n",
        "\n",
        "# Y-axis\n",
        "plt.ylabel('Losses')\n",
        "\n",
        "# Title\n",
        "plt.title('Losses for training and validation')\n",
        " \n",
        "# Legend\n",
        "plt.legend()\n",
        " \n",
        "# Plot\n",
        "plt.show()\n"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d09T0SpEf5RG"
      },
      "source": [
        "***Testing***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdQsC0dqXFnl"
      },
      "source": [
        "#####################################Testing####################################\n",
        "################################################################################\n",
        "\n",
        "# Create root directory for importing test dataset\n",
        "root1 = pathlib.Path.cwd() / \"drive/MyDrive/for_testing\"\n",
        "\n",
        "# For testing dataset\n",
        "test_inputs = get_filenames_of_path(root1 / \"input\")\n",
        "test_targets = get_filenames_of_path(root1 / \"target\")"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81nUjWu4fzYf"
      },
      "source": [
        "*Transformation for testing*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHZOiEuQXuPR"
      },
      "source": [
        "transform_testing = ComposeDouble([  \n",
        "     FunctionWrapperDouble(resize,\n",
        "                          input=True,\n",
        "                          target=False,\n",
        "                          output_shape=(256, 256, 3)),\n",
        "    FunctionWrapperDouble(resize,\n",
        "                          input=False,\n",
        "                          target=True,\n",
        "                          output_shape=(256, 256),\n",
        "                          order=0,\n",
        "                          anti_aliasing=False,\n",
        "                          preserve_range=True),\n",
        "    FunctionWrapperDouble(create_dense_target, input=False, target=True),\n",
        "    FunctionWrapperDouble(np.moveaxis, input = True, \n",
        "                          target = False, source = -1, \n",
        "                          destination=0),\n",
        "])"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXjEJg7dXjXd"
      },
      "source": [
        "# Testing dataset\n",
        "dataset_test = Data_Augmentation(\n",
        "    inputs=test_inputs, targets=test_targets, transform=transform_testing)\n",
        "\n",
        "# Testing dataloader\n",
        "dataloader_testing = DataLoader(dataset=dataset_test, \n",
        "                                 shuffle=True)"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SU39FTcYJaU",
        "outputId": "e7a0f2db-e441-4fe7-dcbe-1051a6349fa2"
      },
      "source": [
        "# Input_test = x and target_test =y\n",
        "x, y = next(iter(dataloader_testing))\n",
        "\n",
        "# Print the shape of test dataset\n",
        "print(f'x = shape: {x.shape}; type: {x.dtype}')\n",
        "print(f'x = min: {x.min()}; max: {x.max()}')\n",
        "print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: FutureWarning: Non RGB image conversion is now deprecated. For RGBA images, please use rgb2gray(rgba2rgb(rgb)) instead. In version 0.19, a ValueError will be raised if input image last dimension length is not 3.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = shape: torch.Size([1, 3, 256, 256]); type: torch.float32\n",
            "x = min: 0.0313725508749485; max: 0.9843137264251709\n",
            "y = shape: torch.Size([1, 256, 256]); class: tensor([0]); type: torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1apIlsxVOWw",
        "outputId": "985ba80a-42b2-4649-83cc-8c001e1b41e8"
      },
      "source": [
        "# Rub testing\n",
        "if __name__ == '__main__':\n",
        " Y_pred1 = model_testing(model, criterion, dataloader_testing, True)\n"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: FutureWarning: Non RGB image conversion is now deprecated. For RGBA images, please use rgb2gray(rgba2rgb(rgb)) instead. In version 0.19, a ValueError will be raised if input image last dimension length is not 3.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " testing progress: 85.71% ...... loss: 0.6543\n",
            "\n",
            " Loss of the network on the 7 test images: 0.5607946770531791\n"
          ]
        }
      ]
    }
  ]
}